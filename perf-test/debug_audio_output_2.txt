
1. Extracting Audio Chunk...
Extracted to D:\mkv-episode-matcher\perf-test\debug_audio\extracted_chunk.wav
Original Audio: SR=16000, Shape=(480011,), Max=0.3001708984375, 
Mean=0.023331038653850555

2. Running Preprocessing...
After Normalize: Max=1.0, Mean=0.0777258574962616
After Noise Reduction: Non-Zero Samples 479749 -> 428571

3. Transcribing...
Transcribing PREPROCESSED file...
[NeMo W 2025-12-25 22:46:38 nemo_logging:405] Megatron num_microbatches_calculator not found, using Apex version.
W1225 22:46:38.896000 23924 Lib\site-packages\torch\distributed\elastic\multiprocessing\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
[NeMo I 2025-12-25 22:46:48 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo W 2025-12-25 22:46:48 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    use_lhotse: true
    skip_missing_manifest_entries: true
    input_cfg: null
    tarred_audio_filepaths: null
    manifest_filepath: null
    sample_rate: 16000
    shuffle: true
    num_workers: 2
    pin_memory: true
    max_duration: 40.0
    min_duration: 0.1
    text_field: answer
    batch_duration: null
    use_bucketing: true
    bucket_duration_bins: null
    bucket_batch_size: null
    num_buckets: 30
    bucket_buffer_size: 20000
    shuffle_buffer_size: 10000
    
[NeMo W 2025-12-25 22:46:48 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    use_lhotse: true
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    max_duration: 40.0
    min_duration: 0.1
    num_workers: 2
    pin_memory: true
    text_field: answer
    
[NeMo I 2025-12-25 22:46:48 nemo_logging:393] PADDING: 0
[NeMo I 2025-12-25 22:46:53 nemo_logging:393] Using RNNT Loss : tdt
    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}
[NeMo I 2025-12-25 22:46:53 nemo_logging:393] Using RNNT Loss : tdt
    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}
[NeMo I 2025-12-25 22:46:53 nemo_logging:393] Using RNNT Loss : tdt
    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}
[NeMo I 2025-12-25 22:46:57 nemo_logging:393] Model EncDecRNNTBPEModel was successfully restored from C:\Users\Jonathan\.cache\huggingface\hub\models--nvidia--parakeet-tdt-0.6b-v2\snapshots\48b630d20b000e5ad3735e5378a2d9bde3f80826\parakeet-tdt-0.6b-v2.nemo.
2025-12-25 22:46:57.568 | INFO     | mkv_episode_matcher.asr_models:load:214 - Loaded Parakeet model: nvidia/parakeet-tdt-0.6b-v2 on cuda
2025-12-25 22:46:57.568 | DEBUG    | mkv_episode_matcher.asr_models:transcribe:305 - Starting Parakeet transcription for D:\mkv-episode-matcher\perf-test\debug_audio\preprocessed_debug.wav
2025-12-25 22:46:57.579 | DEBUG    | mkv_episode_matcher.asr_models:_preprocess_audio:262 - Preprocessed audio saved to C:\Users\Jonathan\AppData\Local\Temp\parakeet_preprocessed\preprocessed_preprocessed_debug.wav
[NeMo W 2025-12-25 22:46:57 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 22:46:57 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 0it [00:07, ?it/s]
2025-12-25 22:47:04.892 | ERROR    | mkv_episode_matcher.asr_models:transcribe:363 - Parakeet transcription failed for D:\mkv-episode-matcher\perf-test\debug_audio\preprocessed_debug.wav: PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\Jonathan\\AppData\\Local\\Temp\\tmpne8i62d3\\manifest.json'
Traceback (most recent call last):
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\mixins\transcription.py", line 370, in transcribe_generator
    processed_outputs = self._transcribe_output_processing(model_outputs, transcribe_cfg)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\models\rnnt_models.py", line 944, in _transcribe_output_processing
    hyp = self.decoding.rnnt_decoder_predictions_tensor(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\rnnt_decoding.py", line 717, in rnnt_decoder_predictions_tensor
    hypotheses_list = self.decoding(
                      ^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\rnnt_greedy_decoding.py", line 201, in __call__
    return self.forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\core\classes\common.py", line 1204, in wrapped_call
    outputs = wrapped(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\rnnt_greedy_decoding.py", line 2887, in forward
    hypotheses = self._greedy_decode(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\rnnt_greedy_decoding.py", line 2927, in _greedy_decode_blank_as_pad_loop_labels
    batched_hyps, alignments, batched_state = self.decoding_computer(
                                              ^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\transducer_decoding\label_looping_base.py", line 217, in __call__
    return self.cuda_graphs_impl(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\transducer_decoding\tdt_label_looping.py", line 765, in cuda_graphs_impl
    self._graph_reinitialize(encoder_output, encoder_output_length)
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\transducer_decoding\tdt_label_looping.py", line 946, in _graph_reinitialize
    self._full_graph_compile()
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\submodules\transducer_decoding\tdt_label_looping.py", line 1029, in _full_graph_compile
    capture_status, _, graph, _, _, _ = cu_call(
                                        ^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\core\utils\cuda_python_utils.py", line 101, in cu_call
    raise Exception(f"CUDA failure! {error}")
Exception: CUDA failure! 35

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jonathan\AppData\Roaming\uv\python\cpython-3.11.10-windows-x86_64-none\Lib\shutil.py", line 632, in _rmtree_unsafe
    os.unlink(fullname)
PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\Jonathan\\AppData\\Local\\Temp\\tmpne8i62d3\\manifest.json'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\mkv-episode-matcher\mkv_episode_matcher\asr_models.py", line 324, in transcribe
    result = self._model.transcribe([preprocessed_audio])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\models\rnnt_models.py", line 306, in transcribe
    return super().transcribe(
           ^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\torch\utils\_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\mixins\transcription.py", line 270, in transcribe
    for processed_outputs in generator:
  File "D:\mkv-episode-matcher\.venv\Lib\site-packages\nemo\collections\asr\parts\mixins\transcription.py", line 351, in transcribe_generator
    with tempfile.TemporaryDirectory() as tmpdir:
  File "C:\Users\Jonathan\AppData\Roaming\uv\python\cpython-3.11.10-windows-x86_64-none\Lib\tempfile.py", line 943, in __exit__
    self.cleanup()
  File "C:\Users\Jonathan\AppData\Roaming\uv\python\cpython-3.11.10-windows-x86_64-none\Lib\tempfile.py", line 947, in cleanup
    self._rmtree(self.name, ignore_errors=self._ignore_cleanup_errors)
  File "C:\Users\Jonathan\AppData\Roaming\uv\python\cpython-3.11.10-windows-x86_64-none\Lib\tempfile.py", line 929, in _rmtree
    _shutil.rmtree(name, onerror=onerror)
  File "C:\Users\Jonathan\AppData\Roaming\uv\python\cpython-3.11.10-windows-x86_64-none\Lib\shutil.py", line 787, in rmtree
    return _rmtree_unsafe(path, onerror)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jonathan\AppData\Roaming\uv\python\cpython-3.11.10-windows-x86_64-none\Lib\shutil.py", line 634, in _rmtree_unsafe
    onerror(os.unlink, fullname, sys.exc_info())
  File "C:\Users\Jonathan\AppData\Roaming\uv\python\cpython-3.11.10-windows-x86_64-none\Lib\tempfile.py", line 893, in onerror
    _os.unlink(path)
PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\Jonathan\\AppData\\Local\\Temp\\tmpne8i62d3\\manifest.json'
Preprocessed Result: ''
Preprocessed Raw: ''
Transcribing ORIGINAL file (bypassing internal preprocess if possible, but 
transcribe calls it)...
Transcribing ORIGINAL file via internal NeMo model directly...
[NeMo W 2025-12-25 22:47:05 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 22:47:05 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00,  9.94it/s]
Transcribing: 1it [00:00,  9.84it/s]
Direct NeMo Result on Original: ''

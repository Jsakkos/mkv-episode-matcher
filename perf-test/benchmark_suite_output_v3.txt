2025-12-25 23:04:13.677 | INFO     | mkv_episode_matcher.config:<module>:19 - Total available threads: 12 -> Setting max to 4
2025-12-25 23:04:13.679 | INFO     | mkv_episode_matcher.__main__:<module>:18 - Starting the application
MKV Episode Matcher Performance Benchmark Tool

Debug: generate_ground_truth using 
test_files_dir=D:\mkv-episode-matcher\perf-test\inputs
Debug: generate_ground_truth 
cache_dir=C:\Users\Jonathan\.mkv-episode-matcher\cache
Debug: found file=Rick and Morty - S01E01.mkv -> show_name=Rick and Morty 
season=1 episode=1
Debug: _has_reference_subtitles checking 
reference_dir=C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and Morty
Debug: _has_reference_subtitles will search for patterns: ['S01E', 'S1E', 
'01x', '1x']
Debug: found 122 srt files in 
C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and Morty
Debug: pattern='S01E' matched 22 files
Added to ground truth: Rick and Morty - S01E01.mkv -> Rick and Morty S1E1
Debug: found file=The Expanse - S01E01.mkv -> show_name=The Expanse season=1 
episode=1
Debug: _has_reference_subtitles checking 
reference_dir=C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse
Debug: _has_reference_subtitles will search for patterns: ['S01E', 'S1E', 
'01x', '1x']
Debug: found 122 srt files in 
C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse
Debug: pattern='S01E' matched 20 files
Added to ground truth: The Expanse - S01E01.mkv -> The Expanse S1E1
+--------------------- Benchmark Configuration ----------------------+
| MKV Episode Matcher Performance Benchmark                          |
| Test files: 2                                                      |
| Iterations per file: 3                                             |
| Models to test: whisper:tiny.en, parakeet:nvidia/parakeet-ctc-0.6b |
| Devices to test: cuda                                              |
+--------------------------------------------------------------------+

Starting benchmark of 2 files across 1 device(s) and 2 model(s)...


Testing on device: cuda

Testing model: whisper:tiny.en
(1/4) Rick and Morty - S01E01.mkv on cuda with whisper:tiny.en
Benchmarking: Rick and Morty - S01E01.mkv (device: cuda, model: 
whisper:tiny.en)
  Running iteration 1/3 on cuda...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  Running iteration 2/3 on cuda...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  Running iteration 3/3 on cuda...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  Running profiled test...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  OK Rick and Morty - S01E01.mkv (cuda, whisper:tiny.en): 4.05s avg, 100.00% 
accuracy

(2/4) The Expanse - S01E01.mkv on cuda with whisper:tiny.en
Benchmarking: The Expanse - S01E01.mkv (device: cuda, model: whisper:tiny.en)
  Running iteration 1/3 on cuda...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.78)
Season: 1, Episode: 1 (confidence: 0.78)
  Running iteration 2/3 on cuda...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.78)
Season: 1, Episode: 1 (confidence: 0.78)
  Running iteration 3/3 on cuda...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.78)
Season: 1, Episode: 1 (confidence: 0.78)
  Running profiled test...
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.78)
Season: 1, Episode: 1 (confidence: 0.78)
  OK The Expanse - S01E01.mkv (cuda, whisper:tiny.en): 1.68s avg, 100.00% 
accuracy


Testing model: parakeet:nvidia/parakeet-ctc-0.6b
(3/4) Rick and Morty - S01E01.mkv on cuda with 
parakeet:nvidia/parakeet-ctc-0.6b
Benchmarking: Rick and Morty - S01E01.mkv (device: cuda, model: 
parakeet:nvidia/parakeet-ctc-0.6b)
  Running iteration 1/3 on cuda...
[NeMo W 2025-12-25 23:04:43 nemo_logging:405] Megatron num_microbatches_calculator not found, using Apex version.
W1225 23:04:43.788000 21780 Lib\site-packages\torch\distributed\elastic\multiprocessing\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
OneLogger: Setting error_handling_strategy to DISABLE_QUIETLY_AND_REPORT_METRIC_ERROR for rank (rank=0) with OneLogger disabled. To override: explicitly set error_handling_strategy parameter.
No exporters were provided. This means that no telemetry data will be collected.
[NeMo I 2025-12-25 23:04:50 nemo_logging:393] Tokenizer SentencePieceTokenizer initialized with 1024 tokens
[NeMo W 2025-12-25 23:04:51 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json
    sample_rate: 16000
    batch_size: 16
    shuffle: true
    num_workers: 8
    pin_memory: true
    use_start_end_token: false
    trim_silence: false
    max_duration: 16.7
    min_duration: 0.1
    is_tarred: false
    tarred_audio_filepaths: null
    shuffle_n: 2048
    bucketing_strategy: fully_randomized
    bucketing_batch_size: null
    
[NeMo W 2025-12-25 23:04:51 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    use_start_end_token: false
    num_workers: 8
    pin_memory: true
    
[NeMo W 2025-12-25 23:04:51 nemo_logging:405] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    batch_size: 16
    shuffle: false
    use_start_end_token: false
    num_workers: 8
    pin_memory: true
    
[NeMo I 2025-12-25 23:04:51 nemo_logging:393] PADDING: 0
[NeMo I 2025-12-25 23:04:59 nemo_logging:393] Model EncDecCTCModelBPE was successfully restored from C:\Users\Jonathan\.cache\huggingface\hub\models--nvidia--parakeet-ctc-0.6b\snapshots\ad09ba1cc62743fbc9814de5d2016fca9096485a\parakeet-ctc-0.6b.nemo.
[NeMo W 2025-12-25 23:05:03 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:03 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s][NeMo W 2025-12-25 23:05:06 nemo_logging:405] CTC decoding strategy 'greedy' is slower than 'greedy_batch', which implements the same exact interface. Consider changing your strategy to 'greedy_batch' for a free performance improvement.

Transcribing: 1it [00:03,  3.37s/it]
Transcribing: 1it [00:03,  3.37s/it]
[NeMo W 2025-12-25 23:05:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00,  3.89it/s]
Transcribing: 1it [00:00,  3.88it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.81)
Season: 1, Episode: 1 (confidence: 0.81)
  Running iteration 2/3 on cuda...
[NeMo W 2025-12-25 23:05:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00, 12.94it/s]
[NeMo W 2025-12-25 23:05:07 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:07 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00, 12.98it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.81)
Season: 1, Episode: 1 (confidence: 0.81)
  Running iteration 3/3 on cuda...
[NeMo W 2025-12-25 23:05:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00, 12.90it/s]
[NeMo W 2025-12-25 23:05:08 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:08 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00, 11.63it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.81)
Season: 1, Episode: 1 (confidence: 0.81)
  Running profiled test...
[NeMo W 2025-12-25 23:05:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00,  9.95it/s]
Transcribing: 1it [00:00,  9.95it/s]
[NeMo W 2025-12-25 23:05:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00, 10.02it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\Rick and 
Morty\Rick and Morty - S01E01.srt (confidence: 0.81)
Season: 1, Episode: 1 (confidence: 0.81)
  OK Rick and Morty - S01E01.mkv (cuda, parakeet:nvidia/parakeet-ctc-0.6b): 
10.69s avg, 100.00% accuracy

(4/4) The Expanse - S01E01.mkv on cuda with parakeet:nvidia/parakeet-ctc-0.6b
Benchmarking: The Expanse - S01E01.mkv (device: cuda, model: 
parakeet:nvidia/parakeet-ctc-0.6b)
  Running iteration 1/3 on cuda...
[NeMo W 2025-12-25 23:05:09 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:09 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00,  9.69it/s]
Transcribing: 1it [00:00,  9.69it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  Running iteration 2/3 on cuda...
[NeMo W 2025-12-25 23:05:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00,  8.89it/s]
Transcribing: 1it [00:00,  8.89it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  Running iteration 3/3 on cuda...
[NeMo W 2025-12-25 23:05:10 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:10 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00,  9.09it/s]
Transcribing: 1it [00:00,  9.09it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  Running profiled test...
[NeMo W 2025-12-25 23:05:11 nemo_logging:405] The following configuration keys are ignored by Lhotse dataloader: use_start_end_token
[NeMo W 2025-12-25 23:05:11 nemo_logging:405] You are using a non-tarred dataset and requested tokenization during data sampling (pretokenize=True). This will cause the tokenization to happen in the main (GPU) process,possibly impacting the training speed if your tokenizer is very large.If the impact is noticable, set pretokenize=False in dataloader config.(note: that will disable token-per-second filtering and 2D bucketing features)

Transcribing: 0it [00:00, ?it/s]
Transcribing: 1it [00:00,  9.09it/s]
Transcribing: 1it [00:00,  9.01it/s]
Matched with C:\Users\Jonathan\.mkv-episode-matcher\cache\data\The Expanse\The 
Expanse - S01E01.srt (confidence: 0.84)
Season: 1, Episode: 1 (confidence: 0.84)
  OK The Expanse - S01E01.mkv (cuda, parakeet:nvidia/parakeet-ctc-0.6b): 0.37s 
avg, 100.00% accuracy

                         Performance Benchmark Results                         
+-----------------------------------------------------------------------------+
|        |        |        |        |   Avg |        |       |        |       |
|        |        |        |        |  Time |        |    F1 | Memory |       |
| File   | Model  | Device | Iteraà |   (s) | Accurà | Score |   (MB) | Statà |
|--------+--------+--------+--------+-------+--------+-------+--------+-------|
| Rick   | whispà | cuda   |      3 |  4.05 | 100.0% | 1.000 | 1325.5 | PASS  |
| and    |        |        |        |       |        |       |        |       |
| Morty  |        |        |        |       |        |       |        |       |
| -      |        |        |        |       |        |       |        |       |
| S01E01 |        |        |        |       |        |       |        |       |
| The    | whispà | cuda   |      3 |  1.68 | 100.0% | 1.000 | 1330.5 | PASS  |
| Expanà |        |        |        |       |        |       |        |       |
| -      |        |        |        |       |        |       |        |       |
| S01E01 |        |        |        |       |        |       |        |       |
| Rick   | parakà | cuda   |      3 | 10.69 | 100.0% | 1.000 | 2135.5 | PASS  |
| and    |        |        |        |       |        |       |        |       |
| Morty  |        |        |        |       |        |       |        |       |
| -      |        |        |        |       |        |       |        |       |
| S01E01 |        |        |        |       |        |       |        |       |
| The    | parakà | cuda   |      3 |  0.37 | 100.0% | 1.000 | 2138.8 | PASS  |
| Expanà |        |        |        |       |        |       |        |       |
| -      |        |        |        |       |        |       |        |       |
| S01E01 |        |        |        |       |        |       |        |       |
+-----------------------------------------------------------------------------+

Benchmark complete!
Detailed report saved to: 
D:\mkv-episode-matcher\perf-test\reports\benchmark_report_20251225_230511.json
